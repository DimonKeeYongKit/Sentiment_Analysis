{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
    "import re, string, random\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('max_columns', None)\n",
    "pd.set_option(\"max_rows\", None)\n",
    "pd.set_option(\"max_colwidth\", 250)\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "clean_tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []\n",
    "\n",
    "# remove all the useless item\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        #remove tag, hashtags, hyperlink\n",
    "        cleanText(token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n' #NOUN\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v' #VERB\n",
    "        else:\n",
    "            pos = 'a' #ADJ\n",
    "            \n",
    "        # this function is to converting a word to its canonical form such as running, ran --> run\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        # remove stop word\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "def cleanText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9_-]+', '', text) # remove tag\n",
    "    text = re.sub(r'#[A-Za-z0-9_-]+', '', text) #remove hashtag\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '', text) #remove hyperlink\n",
    "    text = re.sub(r'[\\n]+', '', text) #remove nextline\n",
    "    text = re.sub(r'RT : ', '', text) #remove RT\n",
    "    return text\n",
    "\n",
    "#takes a list of tweets as an argument to provide a list of words in all of the tweet tokens joined.\n",
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token #yield is use in a generator, func are almost same with return\n",
    "\n",
    "            \n",
    "# preparation for passing data list into model\n",
    "#convert into dictionary(word as key, true as value)\n",
    "def get_tweets_for_model(cleaned_tokens_list):\n",
    "    for tweet_tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tweet_tokens)\n",
    "        \n",
    "        \n",
    "def preRUN():\n",
    "    positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "    negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "    # text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "    # tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    positive_tweet_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "    negative_tweet_tokens = twitter_samples.tokenized('negative_tweets.json')\n",
    "\n",
    "    positive_cleaned_tokens_list = []\n",
    "    negative_cleaned_tokens_list = []\n",
    "\n",
    "    for tokens in positive_tweet_tokens:\n",
    "        positive_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "    for tokens in negative_tweet_tokens:\n",
    "        negative_cleaned_tokens_list.append(remove_noise(tokens, stop_words))\n",
    "\n",
    "    all_pos_words = get_all_words(positive_cleaned_tokens_list)\n",
    "\n",
    "    freq_dist_pos = FreqDist(all_pos_words)\n",
    "    # print(freq_dist_pos.most_common(10))\n",
    "\n",
    "    positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens_list)\n",
    "    negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens_list)\n",
    "\n",
    "    positive_dataset = [(tweet_dict, \"Positive\")\n",
    "                         for tweet_dict in positive_tokens_for_model]\n",
    "\n",
    "    negative_dataset = [(tweet_dict, \"Negative\")\n",
    "                         for tweet_dict in negative_tokens_for_model]\n",
    "\n",
    "    dataset = positive_dataset + negative_dataset\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    train_data = dataset[:7000]\n",
    "    test_data = dataset[7000:]\n",
    "    global classifier\n",
    "    classifier = NaiveBayesClassifier.train(train_data)\n",
    "    global A\n",
    "    A = classify.accuracy(classifier, test_data)\n",
    "    \n",
    "def NBSentimentAnalysis(custom_tweet):\n",
    "    custom_tokens = remove_noise(word_tokenize(custom_tweet))\n",
    "    answer = classifier.classify(dict([token, True] for token in custom_tokens))\n",
    "    return answer\n",
    "    \n",
    "def searchInTwitter():\n",
    "    # get the API key\n",
    "    log = pd.read_csv('TwitterAPI.csv')\n",
    "\n",
    "    # Authentication\n",
    "    consumerKey = log['key'][0]\n",
    "    consumerSecret = log['secret'][0]\n",
    "    accessToken = log['token'][0]\n",
    "    accessTokenSecret = log['tokenSecret'][0]\n",
    "\n",
    "    # Create the authentication object\n",
    "    auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "    # Set the access token and token secret\n",
    "    auth.set_access_token(accessToken, accessTokenSecret)\n",
    "    #create api object\n",
    "    api = tweepy.API(auth, wait_on_rate_limit = True)\n",
    "\n",
    "    \n",
    "    #---------------------------------------------------------------------------UI PART\n",
    "    # Define the window's contents\n",
    "    layout = [  [sg.Text(\"Please enter keyword or hashtag to search: \")],\n",
    "              [sg.Input()],\n",
    "              [sg.Text(\"Please enter how many tweets to analyze: \")],\n",
    "              [sg.Input()],\n",
    "              [sg.Button('OK')] ]\n",
    "\n",
    "    # Create the window\n",
    "    window = sg.Window('Sentiment Analysis System', layout)\n",
    "    # Display and interact with the Window\n",
    "    event, values = window.read()\n",
    "    # Finish up by removing from the screen\n",
    "    window.close()\n",
    "    #---------------------------------------------------------------------------UI PART\n",
    "    \n",
    "    # extract what item what quantity to crawl\n",
    "    global keyword\n",
    "    keyword = values[0]\n",
    "    noOfTweet = int(values[1])\n",
    "    posts = tweepy.Cursor(api.search, q=keyword, lang=\"en\").items(noOfTweet)\n",
    "\n",
    "    print(\"These is the post:\")\n",
    "    i = 1\n",
    "    for post in posts:\n",
    "        tweet_list.append(post.text)\n",
    "        print(\"  \"+str(i)+\")\"+post.text)\n",
    "        print(\"\\n\\n\");\n",
    "        i += 1\n",
    "\n",
    "def getSubjectivity(text):\n",
    "    #the range of [0,1], 1 means a public opinion and not a factual information\n",
    "    return TextBlob(text).sentiment.subjectivity \n",
    "\n",
    "def getPolarity(text):\n",
    "    #the range of [-1,1], -1 means negatif , 1 means positif\n",
    "    return TextBlob(text).sentiment.polarity \n",
    "\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    elif score > 0:\n",
    "        return 'Positive'\n",
    "    \n",
    "def uiNB():\n",
    "    window2 = sg.Window(\"Percentage of TB_Analysis\", [  [sg.Text(\"Positive percentage : \"+ str(posp))],\n",
    "          [sg.Text(\"Neutral percentage : \"+ str(neup))],\n",
    "          [sg.Text(\"Negative percentage : \"+ str(negp))],\n",
    "          [sg.Button('Show BarChart')],\n",
    "          [sg.Button('Show PieChart')] ])\n",
    "    while True:\n",
    "        e,v = window2.read()\n",
    "        if e == \"Show BarChart\":\n",
    "            getBarChartTB()\n",
    "        elif e == \"Show PieChart\":\n",
    "            getPieChart()\n",
    "        elif e == sg.WIN_CLOSED:\n",
    "            break\n",
    "\n",
    "def uiTB():\n",
    "    window3 = sg.Window(\"Percentage of NB_Analysis\", [  [sg.Text(\"Positive percentage : \"+ str(posp))],\n",
    "          [sg.Text(\"Neutral percentage : \"+ str(neup))],\n",
    "          [sg.Text(\"Negative percentage : \"+ str(negp))],\n",
    "          [sg.Button('Show BarChart')],\n",
    "          [sg.Button('Show PieChart')] ])\n",
    "    while True:\n",
    "        e,v = window3.read()\n",
    "        if e == \"Show BarChart\":\n",
    "            getBarChartNB()\n",
    "        elif e == \"Show PieChart\":\n",
    "            getPieChart()\n",
    "        elif e == sg.WIN_CLOSED:\n",
    "            break\n",
    "    \n",
    "def TextBlobSentimentAnalysis():\n",
    "    global df\n",
    "    df = pd.DataFrame([tweet for tweet in tweet_list], columns=['Tweet'])\n",
    "    df['Tweet'] = df['Tweet'].apply(cleanText)\n",
    "    df['Subjectivity'] = df['Tweet'].apply(getSubjectivity)\n",
    "    df['Polarity'] = df['Tweet'].apply(getPolarity)\n",
    "    df['TB_Analysis'] = df['Polarity'].apply(getAnalysis)\n",
    "    df['NB_Analysis'] = df['Tweet'].apply(NBSentimentAnalysis)\n",
    "    print('-----------------------------------------------------')\n",
    "    df.head()\n",
    "    global ddf\n",
    "    ddf = pd.DataFrame([tweet for tweet in tweet_list], columns=['Tweet'])\n",
    "    ddf['Tweet'] = ddf['Tweet'].apply(cleanText)\n",
    "  \n",
    "    \n",
    "    #---------------------------------------------------------------------------UI PART\n",
    "    sg.set_options(auto_size_buttons=True)\n",
    "    data = []\n",
    "    layout = [\n",
    "        [sg.Text(\"List of tweet\")],\n",
    "        [sg.Table(values=ddf.values.tolist(),\n",
    "                  headings=list(ddf.columns.values),\n",
    "                  display_row_numbers=True, col_widths=500,\n",
    "                  num_rows=max(10,len(data))\n",
    "                 )],\n",
    "        [sg.Button(\"Show system accuracy\"),sg.Button(\"Show the sentiment analysis\"), sg.Button(\"Cancel\")]\n",
    "    ]\n",
    "    window = sg.Window('Tweet Table', layout, grab_anywhere=False)\n",
    "    global posp\n",
    "    global neup\n",
    "    global negp\n",
    "\n",
    "    while True:\n",
    "        event, values = window.read()\n",
    "        if event == \"Show system accuracy\":\n",
    "            print(\"The accuracy is :\",str(A))\n",
    "            classifier.show_most_informative_features(20)\n",
    "        elif event == \"Show the sentiment analysis\":\n",
    "            \n",
    "            window4 = sg.Window('Result of Analysis',\n",
    "                                [ [sg.Text(\"List of tweet with analysis\")],\n",
    "                                [sg.Table(values=df.values.tolist(),\n",
    "                                          headings=list(df.columns.values),\n",
    "                                          display_row_numbers=True,\n",
    "                                          auto_size_columns=True,\n",
    "                                          num_rows=max(10,len(data))\n",
    "                                         )],\n",
    "                                 [sg.Button(\"Show percentage of TB_Analysis\"),\n",
    "                                  sg.Button(\"Show percentage of NB_Analysis\")]], grab_anywhere=False)\n",
    "            \n",
    "            while True:\n",
    "                event4, value4 = window4.read()\n",
    "                if event4 == \"Show percentage of TB_Analysis\":\n",
    "                    postweets = df[df.TB_Analysis == 'Positive']\n",
    "                    postweets = postweets['Tweet']\n",
    "                    posp = round(postweets.shape[0] / df.shape[0] * 100, 1)\n",
    "\n",
    "                    neutweets = df[df.TB_Analysis == 'Neutral']\n",
    "                    neutweets = neutweets['Tweet']\n",
    "                    neup = round(neutweets.shape[0] / df.shape[0] * 100, 1)\n",
    "\n",
    "                    negtweets = df[df.TB_Analysis == 'Negative']\n",
    "                    negtweets = negtweets['Tweet']\n",
    "                    negp = round(negtweets.shape[0] / df.shape[0] * 100, 1)\n",
    "\n",
    "                    uiTB()\n",
    "\n",
    "                elif event4 == \"Show percentage of NB_Analysis\":\n",
    "                    postweets = df[df.NB_Analysis == 'Positive']\n",
    "                    postweets = postweets['Tweet']\n",
    "                    posp = round(postweets.shape[0] / df.shape[0] * 100, 1)\n",
    "\n",
    "                    neutweets = df[df.NB_Analysis == 'Neutral']\n",
    "                    neutweets = neutweets['Tweet']\n",
    "                    neup = round(neutweets.shape[0] / df.shape[0] * 100, 1)\n",
    "\n",
    "                    negtweets = df[df.NB_Analysis == 'Negative']\n",
    "                    negtweets = negtweets['Tweet']\n",
    "                    negp = round(negtweets.shape[0] / df.shape[0] * 100, 1)\n",
    "\n",
    "                    uiNB()\n",
    "                elif event4 == sg.WIN_CLOSED:\n",
    "                    break\n",
    "        elif event == \"Cancel\":\n",
    "            break\n",
    "        elif event == sg.WIN_CLOSED:\n",
    "            break\n",
    "    window.close()\n",
    "    #---------------------------------------------------------------------------UI PART\n",
    "    \n",
    "\n",
    "\n",
    "def getBarChartTB():\n",
    "    # show the value counts in bar chart\n",
    "    plt.title(\"TB_Analysis Value Counts\")\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    df['TB_Analysis'].value_counts().plot(kind='bar')\n",
    "    plt.show()\n",
    "def getBarChartNB():\n",
    "    # show the value counts in bar chart\n",
    "    plt.title(\"NB_Analysis Value Counts\")\n",
    "    plt.xlabel(\"Sentiment\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    df['NB_Analysis'].value_counts().plot(kind='bar')\n",
    "    plt.show()\n",
    "\n",
    "def getPieChart():\n",
    "    #Creating PieCart\n",
    "    labels = ['Positive ['+str(posp)+'%]' , 'Neutral ['+str(neup)+'%]','Negative ['+str(negp)+'%]']\n",
    "    sizes = [posp, neup, negp]\n",
    "    colors = [\"yellowgreen\", \"blue\",\"red\"]\n",
    "    patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "    plt.legend(labels)\n",
    "    plt.title(\"Sentiment Analysis Result for keyword = \"+keyword+\"\" )\n",
    "    plt.axis(\"equal\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    #---------------------------------------------------------------------------UI PART\n",
    "    # Define the window's contents\n",
    "    layout = [  [sg.Text(\"Thanks for using this Sentiment Analysis System.\")],\n",
    "              [sg.Text(\"Please wait about 30 seconds for the machine to prepare\")],\n",
    "              [sg.Button('OK')] ]\n",
    "\n",
    "    # Create the window\n",
    "    window = sg.Window('Sentiment Analysis System', layout)\n",
    "    # Display and interact with the Window\n",
    "    event, values = window.read()\n",
    "    # Finish up by removing from the screen\n",
    "    window.close()\n",
    "    #---------------------------------------------------------------------------UI PART\n",
    "    preRUN()\n",
    "    searchInTwitter()\n",
    "    TextBlobSentimentAnalysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
